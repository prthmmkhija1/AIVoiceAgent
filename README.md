# AI Voice Agent

A real-time AI voice assistant that enables natural spoken conversations. Built with **Deepgram** for speech processing (STT & TTS), **Grok (X.AI)** as the LLM backbone, and **WebSocket** streaming for low-latency bidirectional audio communication.

**Author:** Pratham Makhija

---

## Table of Contents

- [Features](#features)
- [Project Structure](#project-structure)
- [Architecture & Data Flow](#architecture--data-flow)
- [Requirements Implementation](#requirements-implementation)
- [Installation](#installation)
- [Configuration](#configuration)
- [Usage](#usage)
- [How It Works](#how-it-works)
- [API & Services Reference](#api--services-reference)
- [Client Interface](#client-interface)
- [Troubleshooting](#troubleshooting)

---

## Features

- **Real-time Speech-to-Text** â€” Deepgram Nova-2 streaming transcription with interim results
- **LLM Integration** â€” Grok (X.AI) via OpenAI-compatible API (easily swappable to OpenAI / Anthropic)
- **Consistent AI Persona** â€” "Nova", a friendly voice-optimized assistant with defined personality traits
- **Conversation Memory** â€” Sliding window with optional LLM-powered summarization for context compaction
- **Text-to-Speech** â€” Deepgram Aura TTS converting LLM responses to natural-sounding speech
- **WebSocket Streaming** â€” Chunked audio delivery with latency optimization
- **Error Handling & Reconnection** â€” Exponential backoff reconnection, graceful degradation, fallback responses

---

## Project Structure

```
voice-agent/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ config.js                  # Central configuration (API keys, STT/TTS/LLM settings)
â”‚   â”œâ”€â”€ ws/
â”‚   â”‚   â””â”€â”€ wsHandler.js               # WebSocket server (binary audio + JSON control messages)
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ deepgram/
â”‚   â”‚   â”‚   â”œâ”€â”€ stt.js                 # Deepgram streaming Speech-to-Text
â”‚   â”‚   â”‚   â””â”€â”€ tts.js                 # Deepgram Text-to-Speech
â”‚   â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”‚   â”œâ”€â”€ provider.js            # LLM provider (Grok/OpenAI/Anthropic abstraction)
â”‚   â”‚   â”‚   â””â”€â”€ persona.js             # AI persona definition & system prompt
â”‚   â”‚   â””â”€â”€ memory/
â”‚   â”‚       â””â”€â”€ conversationMemory.js  # Per-session conversation history management
â”‚   â””â”€â”€ app.js                         # Main orchestrator â€” connects all services
â”œâ”€â”€ client.html                        # Browser-based test client (mic capture + audio playback)
â”œâ”€â”€ .env                               # Environment variables (API keys â€” not committed)
â”œâ”€â”€ .gitignore                         # Git ignore rules
â”œâ”€â”€ package.json                       # Project metadata & dependencies
â””â”€â”€ README.md                          # This file
```

---

## Architecture & Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     WebSocket      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚              Node.js Server                  â”‚
â”‚  client.html â”‚   Binary Audio +   â”‚                                              â”‚
â”‚              â”‚   JSON Messages    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  ğŸ¤ Mic â”€â”€â”€â”€â”€â”€â–º WS Handler â”€â”€â”€â”€â”€â”€â”€â”€â–º STT      â”‚  â”‚  LLM    â”‚  â”‚   Memory    â”‚  â”‚
â”‚              â”‚                    â”‚  â”‚(Deepgram)â”œâ”€â”€â–º(Grok)   â”œâ”€â”€â–º(Sliding Win)â”‚  â”‚
â”‚  ğŸ”Š Speakerâ—„â”€â”€â”€â”€ WS Handler â—„â”€â”€â”€â”€â”€â”€â”¤ TTS      â”‚â—„â”€â”¤+Persona â”‚  â”‚+Summarize   â”‚  â”‚
â”‚              â”‚                    â”‚  â”‚(Deepgram)â”‚  â”‚         â”‚  â”‚             â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Flow:**

1. User speaks â†’ browser captures mic audio (linear16, 16kHz)
2. Audio streams to server via WebSocket (binary frames)
3. Server forwards audio to **Deepgram STT** for real-time transcription
4. On utterance end (silence detection), the complete transcript is sent to the **Grok LLM**
5. LLM generates a response using the **persona** system prompt and **conversation memory**
6. Response text is converted to speech via **Deepgram TTS**
7. TTS audio is streamed back to the client in chunks for low-latency playback

---

## Requirements Implementation

### 1. Deepgram Streaming STT (Speech-to-Text)

- **File:** `src/services/deepgram/stt.js`
- Uses Deepgram's `listen.live()` WebSocket streaming API
- Nova-2 model with smart formatting, punctuation, and Voice Activity Detection (VAD)
- Interim results for real-time feedback, `UtteranceEnd` event for turn detection
- Connection health: waits for WebSocket `Open` event before sending audio

### 2. LLM Integration (Grok / OpenAI / Anthropic)

- **File:** `src/services/llm/provider.js`
- Currently configured for **Grok (X.AI)** â€” `grok-3` model via `https://api.x.ai/v1`
- Uses the `openai` npm package (X.AI provides OpenAI-compatible API)
- Supports both **streaming** (`streamResponse()`) and **non-streaming** (`generateResponse()`) modes
- Easily switchable: change `baseURL`, `model`, and API key in `config.js` to use OpenAI or any compatible provider

### 3. Consistent AI Persona

- **File:** `src/services/llm/persona.js`
- Persona name: **Nova** â€” a friendly, warm AI voice assistant
- Defined personality traits: friendly, patient, knowledgeable, concise, conversational
- Voice-specific guidelines: short responses (2-4 sentences), no markdown/code blocks, natural speech patterns
- System prompt injected into every LLM request via `getSystemPrompt()`

### 4. Conversation Memory (Sliding Window + Summarization)

- **File:** `src/services/memory/conversationMemory.js`
- Per-session memory using `Map<sessionId, {messages, summary}>`
- **Sliding window**: keeps the last N messages (configurable, default 20)
- **Optional summarization**: when history exceeds threshold, uses LLM to summarize older messages into a compact paragraph, preserving context while reducing token usage
- Supports multiple concurrent sessions (each WebSocket client gets isolated memory)

### 5. Deepgram TTS (Text-to-Speech)

- **File:** `src/services/deepgram/tts.js`
- Uses Deepgram's `speak.request()` API with the Aura Asteria voice model
- Output: raw linear16 audio at 24kHz sample rate
- Two modes: `synthesize()` returns full audio buffer, `streamSynthesize()` streams chunks via callback

### 6. WebSocket Streaming & Latency Optimization

- **File:** `src/ws/wsHandler.js` + `src/app.js`
- Binary WebSocket protocol: audio data sent as raw binary frames (no base64 encoding overhead)
- JSON messages for control signals (transcripts, status updates, errors)
- Audio chunked into 4KB segments with `setImmediate()` between chunks (non-blocking I/O)
- Heartbeat ping/pong every 30 seconds for connection health monitoring
- Streamed LLM responses (`streamAndCollect()`) for lower time-to-first-token

### 7. Error Handling & Reconnect Logic

- **Files:** All service files + `src/app.js`
- **STT reconnection**: exponential backoff (1s â†’ 2s â†’ 4s â†’ 8s â†’ 10s cap), max 5 attempts
- **LLM error handling**: try/catch on all API calls, fallback TTS error message sent to client
- **WebSocket**: dead connection detection via ping/pong, automatic cleanup on disconnect
- **Graceful shutdown**: handles SIGINT/SIGTERM, closes all connections, cleans up sessions
- **Uncaught exceptions & unhandled rejections**: caught at process level with logging

---

## Installation

### Prerequisites

- **Node.js** v18 or higher
- **Deepgram API Key** â€” [Get one here](https://console.deepgram.com) (free $200 credit)
- **Grok API Key** â€” [Get one here](https://console.x.ai)

### Steps

```bash
# 1. Clone the repository
git clone <repository-url>
cd voice-agent

# 2. Install dependencies
npm install

# 3. Create environment file
# Copy .env.example or create .env with your API keys (see Configuration below)
```

---

## Configuration

Create a `.env` file in the project root:

```env
# Deepgram API Key (Required) â€” used for both STT and TTS
DEEPGRAM_API_KEY=your_deepgram_api_key_here

# Grok API Key (Required) â€” used for LLM conversation
GROK_API_KEY=your_xai_api_key_here

# Server Config (Optional)
WS_PORT=8080

# Memory Settings (Optional)
MAX_CONVERSATION_HISTORY=20
USE_SUMMARIZATION=false
```

All settings can be fine-tuned in `src/config/config.js`:
| Setting | Default | Description |
|---------|---------|-------------|
| STT Model | `nova-2` | Deepgram transcription model |
| TTS Model | `aura-asteria-en` | Deepgram voice (female, natural) |
| LLM Model | `grok-3` | X.AI Grok model |
| LLM Temperature | `0.7` | Response creativity (0-1) |
| Max Tokens | `300` | Keep responses concise for voice |
| Memory Window | `20` | Messages kept in sliding window |
| Utterance End | `1000ms` | Silence threshold to finalize speech |

---

## Usage

```bash
# Start the server
npm start

# Or with auto-restart on file changes (development)
npm run dev
```

**Expected output:**

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     ğŸ™ï¸  AI Voice Agent Starting      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Configuration validated
âœ… [STT] Service ready
âœ… [TTS] Service ready
âœ… [LLM] Initialized with Grok (grok-3)
ğŸ‘¤ [LLM] Persona: Nova - AI Voice Assistant
âœ… [WS] Server listening on ws://localhost:8080

ğŸ§ Waiting for client connections...
```

Then open `client.html` in your browser to start a voice conversation.

---

## Client Interface

The included `client.html` provides a browser-based test interface:

- **Start/Stop** button to begin/end voice capture
- **Real-time transcript** display (interim + final results)
- **AI response** text display
- **Audio playback** of TTS responses
- Captures microphone audio as linear16 at 16kHz
- Connects to `ws://localhost:8080` automatically

---

## Troubleshooting

| Issue                         | Solution                                            |
| ----------------------------- | --------------------------------------------------- |
| "Missing API keys" on startup | Check `.env` file exists with valid keys            |
| No transcripts appearing      | Ensure microphone permission is granted in browser  |
| LLM returns errors            | Verify your Grok API key starts with `xai-`         |
| Port 8080 already in use      | Change `WS_PORT` in `.env` or kill existing process |
| STT connection timeout        | Check internet connection and Deepgram API key      |
| Audio not playing in browser  | Use Chrome/Edge (best Web Audio API support)        |
