# ğŸ™ï¸ AI Voice Agent

A real-time AI voice conversation agent built with **Python**. It enables natural, human-like voice interactions using **Deepgram** for speech-to-text & text-to-speech, **Grok (X.AI)** LLM for intelligent responses, and a **WebSocket** pipeline for low-latency bidirectional audio streaming â€” with sentence-level streaming, barge-in support, automatic error recovery, and latency tracking.

**Author:** Pratham Makhija

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          WebSocket Client                          â”‚
â”‚                  (any app sending/receiving audio)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚  binary: mic audio (16kHz PCM)   â”‚  binary: TTS audio (24kHz PCM)
               â”‚  json: control messages           â”‚  json: transcripts, status
               â–¼                                   â–²
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     WebSocket Server (ws_handler.py)                â”‚
â”‚              â€¢ Session management (per-client UUID)                 â”‚
â”‚              â€¢ Binary/JSON protocol routing                        â”‚
â”‚              â€¢ Chunked audio streaming + heartbeat                 â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                                                   â–²
       â–¼                                                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Deepgram    â”‚    â”‚   LLM        â”‚    â”‚  Deepgram TTS               â”‚
â”‚  STT         â”‚    â”‚   Provider   â”‚    â”‚  (tts.py)                   â”‚
â”‚  (stt.py)    â”‚    â”‚ (provider.py)â”‚    â”‚                             â”‚
â”‚              â”‚    â”‚              â”‚    â”‚  â€¢ Aura Asteria voice       â”‚
â”‚  â€¢ Nova-2    â”‚    â”‚  â€¢ Grok-3    â”‚    â”‚  â€¢ Sentence-level synthesis â”‚
â”‚  â€¢ Streaming â”‚â”€â”€â”€â–¶â”‚    (X.AI)    â”‚â”€â”€â”€â–¶â”‚  â€¢ Retry w/ backoff        â”‚
â”‚  â€¢ VAD       â”‚    â”‚  â€¢ OpenAI-   â”‚    â”‚  â€¢ 24kHz linear16 output   â”‚
â”‚  â€¢ Interim + â”‚    â”‚    compat SDKâ”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚    final     â”‚    â”‚              â”‚
â”‚  â€¢ Keepalive â”‚    â”‚  â€¢ Streaming â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â€¢ Reconnect â”‚    â”‚  â€¢ Retry     â”‚    â”‚  Conversation Memory        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â€¢ Persona â—€â”€â”€â”€â”€â”€â”‚  (conversation_memory.py)   â”‚
                    â”‚    injection â”‚    â”‚                             â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â€¢ Per-session history      â”‚
                                        â”‚  â€¢ Sliding window (max 20) â”‚
                                        â”‚  â€¢ Optional summarization  â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

```
  User speaks â†’ WebSocket â†’ Deepgram STT â†’ Transcript (text)
                                                  â†“
                                           Memory (add user msg)
                                                  â†“
                                        LLM stream (+ Persona + History)
                                                  â†“
                                       Sentence detection (regex)
                                                  â†“
                                         Deepgram TTS (per sentence)
                                                  â†“
                                     WebSocket â† Audio chunks â†’ User hears
```

---

## Features

| Feature                    | Description                                                                    |
| -------------------------- | ------------------------------------------------------------------------------ |
| ğŸ—£ï¸ **Real-time STT**       | Deepgram Nova-2 streaming transcription with interim results & VAD             |
| ğŸ§  **LLM Integration**     | Grok-3 (X.AI) via OpenAI-compatible SDK for conversation handling              |
| ğŸ‘¤ **AI Persona**          | "Nova" â€” a friendly, voice-optimized assistant with consistent personality     |
| ğŸ’¾ **Conversation Memory** | Sliding window + optional LLM-powered summarization for context compaction     |
| ğŸ”Š **Sentence-Level TTS**  | Deepgram Aura TTS with sentence-by-sentence streaming for faster time-to-voice |
| âš¡ **Barge-In Support**    | Users can interrupt the AI mid-response â€” server-side cancellation             |
| ğŸ”„ **Retry & Reconnect**   | Exponential backoff with jitter on all external API calls + STT auto-reconnect |
| ğŸ“Š **Latency Metrics**     | End-to-end pipeline latency tracking: STT â†’ LLM â†’ TTS per request              |
| ğŸŒ **WebSocket Streaming** | Binary audio + JSON control protocol with chunked delivery & heartbeat         |
| ğŸ›¡ï¸ **Error Handling**      | Graceful degradation, fallback TTS responses, clean session teardown           |

---

## Project Structure

```
voice-agent/
â”œâ”€â”€ main.py                                 # Entry point â€” orchestrates all services
â”œâ”€â”€ requirements.txt                        # Python dependencies
â”œâ”€â”€ README.md
â””â”€â”€ app/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ config/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ config.py                       # Central configuration (API keys, models, settings)
    â”œâ”€â”€ ws/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ ws_handler.py                   # WebSocket server (binary audio + JSON control)
    â””â”€â”€ services/
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ deepgram/
        â”‚   â”œâ”€â”€ __init__.py
        â”‚   â”œâ”€â”€ stt.py                      # Deepgram streaming Speech-to-Text
        â”‚   â””â”€â”€ tts.py                      # Deepgram Text-to-Speech (with retry)
        â”œâ”€â”€ llm/
        â”‚   â”œâ”€â”€ __init__.py
        â”‚   â”œâ”€â”€ provider.py                 # Grok LLM provider (OpenAI-compatible SDK)
        â”‚   â””â”€â”€ persona.py                  # AI persona definition & system prompt
        â””â”€â”€ memory/
            â”œâ”€â”€ __init__.py
            â””â”€â”€ conversation_memory.py      # Per-session conversation history management
```

---

## Installation

### Prerequisites

- **Python 3.10+**
- **Deepgram API Key** â€” [console.deepgram.com](https://console.deepgram.com)
- **Grok API Key** â€” [console.x.ai](https://console.x.ai)

### Steps

```bash
# 1. Navigate to project
cd voice-agent

# 2. Create a virtual environment (recommended)
python -m venv venv
source venv/bin/activate        # Linux/macOS
# or
venv\Scripts\activate           # Windows

# 3. Install dependencies
pip install -r requirements.txt

# 4. Create .env file
cp .env.example .env
# Edit .env and add your API keys
```

---

## Configuration

Create a `.env` file in the project root:

```env
DEEPGRAM_API_KEY=your_deepgram_api_key_here
GROK_API_KEY=your_grok_api_key_here

# Optional overrides
# LLM_MODEL=grok-3
# LLM_TEMPERATURE=0.7
# LLM_MAX_TOKENS=300
WS_PORT=8080
```

All settings (STT model, TTS voice, LLM model, memory strategy, etc.) can be adjusted in `app/config/config.py`.

---

## Usage

```bash
# Start the voice agent server
python main.py
```

The server starts a WebSocket endpoint at `ws://localhost:8080`. Connect any WebSocket client that sends raw audio (linear16, 16 kHz, mono) as binary frames and handles the JSON + binary response protocol described below.

---

## WebSocket Protocol

### Client â†’ Server

| Data Type | Description                                               |
| --------- | --------------------------------------------------------- |
| Binary    | Raw audio chunks (linear16, 16 kHz, mono)                 |
| JSON      | Control messages: `{type: 'end' / 'clear' / 'interrupt'}` |

### Server â†’ Client

| Message Type        | Description                      |
| ------------------- | -------------------------------- |
| `connected`         | Session established              |
| `transcript`        | STT result (interim or final)    |
| `thinking`          | LLM is generating a response     |
| `speaking`          | TTS audio streaming started      |
| `audio_start`       | Audio stream beginning           |
| Binary data         | TTS audio chunks                 |
| `audio_end`         | Audio stream complete            |
| `audio_interrupted` | Barge-in: response was cancelled |
| `response`          | Full AI response text            |
| `error`             | Error message                    |

---

## Tech Stack

| Component      | Technology                         |
| -------------- | ---------------------------------- |
| **Runtime**    | Python 3.10+ / asyncio             |
| **WebSocket**  | websockets                         |
| **STT**        | Deepgram Nova-2 (streaming)        |
| **TTS**        | Deepgram Aura (Asteria voice)      |
| **LLM**        | Grok-3 (X.AI)                      |
| **LLM Client** | openai SDK (OpenAI-compatible API) |
| **Config**     | python-dotenv                      |
