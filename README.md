# ğŸ™ï¸ AI Voice Agent

A real-time AI voice conversation agent built with **Python**. It enables natural, human-like voice interactions using **Deepgram** for speech-to-text & text-to-speech, **Groq LLM** for intelligent responses, and a **WebSocket** pipeline for low-latency bidirectional audio streaming â€” with sentence-level streaming, barge-in support, automatic error recovery, and latency tracking. Includes a ready-to-use browser client (`client.html`).

**Author:** Pratham Makhija

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     client.html  (Browser UI)                            â”‚
â”‚          Mic capture (16kHz linear16) â†â†’ TTS playback (24kHz)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                               â”‚
                    â”‚  binary: mic audio (16kHz)     â”‚  binary: TTS audio (24kHz)
                    â”‚  json:   control messages      â”‚  json:   transcripts, status
                    â–¼                               â–²
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      WebSocket Server (ws_handler.py)                    â”‚
â”‚                                                                          â”‚
â”‚          â€¢ Session management (per-client UUID)                          â”‚
â”‚          â€¢ Binary / JSON protocol routing                                â”‚
â”‚          â€¢ Chunked audio streaming + heartbeat                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                               â–²
                    â–¼                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Deepgram STT       â”‚  â”‚    LLM Provider       â”‚  â”‚    Deepgram TTS       â”‚
â”‚    (stt.py)           â”‚  â”‚    (provider.py)       â”‚  â”‚    (tts.py)           â”‚
â”‚                       â”‚  â”‚                       â”‚  â”‚                       â”‚
â”‚  â€¢ Nova-2 model       â”‚  â”‚  â€¢ Groq (default)    â”‚  â”‚  â€¢ Aura Asteria voice â”‚
â”‚  â€¢ Streaming          â”‚â”€â–¶â”‚  â€¢ OpenAI-compat SDK  â”‚â”€â–¶â”‚  â€¢ Sentence-level     â”‚
â”‚  â€¢ VAD events         â”‚  â”‚  â€¢ Token streaming    â”‚  â”‚    synthesis           â”‚
â”‚  â€¢ Interim + final    â”‚  â”‚  â€¢ Retry w/ backoff   â”‚  â”‚  â€¢ Retry w/ backoff   â”‚
â”‚  â€¢ Keepalive          â”‚  â”‚  â€¢ Persona injection  â”‚  â”‚  â€¢ 24kHz linear16     â”‚
â”‚  â€¢ Auto-reconnect     â”‚  â”‚                       â”‚  â”‚                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â–¼
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚   Conversation Memory      â”‚
                           â”‚  (conversation_memory.py)  â”‚
                           â”‚                            â”‚
                           â”‚  â€¢ Per-session history     â”‚
                           â”‚  â€¢ Sliding window (max 20) â”‚
                           â”‚  â€¢ Optional summarization  â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

```
  User speaks â†’ WebSocket â†’ Deepgram STT â†’ Transcript (text)
                                                  â†“
                                           Memory (add user msg)
                                                  â†“
                                        LLM stream (+ Persona + History)
                                                  â†“
                                       Sentence detection (regex)
                                                  â†“
                                         Deepgram TTS (per sentence)
                                                  â†“
                                     WebSocket â† Audio chunks â†’ User hears
```

---

## Features

| Feature                    | Description                                                                    |
| -------------------------- | ------------------------------------------------------------------------------ |
| ğŸ—£ï¸ **Real-time STT**       | Deepgram Nova-2 streaming transcription with interim results & VAD             |
| ğŸ§  **LLM Integration**     | Groq (default) / Grok / OpenAI / Anthropic â€” switchable via env variable       |
| ğŸ‘¤ **AI Persona**          | "Nova" â€” a friendly, voice-optimized assistant with consistent personality     |
| ğŸ’¾ **Conversation Memory** | Sliding window + optional LLM-powered summarization for context compaction     |
| ğŸ”Š **Sentence-Level TTS**  | Deepgram Aura TTS with sentence-by-sentence streaming for faster time-to-voice |
| âš¡ **Barge-In Support**    | Users can interrupt the AI mid-response â€” server-side cancellation             |
| ğŸ”„ **Retry & Reconnect**   | Exponential backoff with jitter on all external API calls + STT auto-reconnect |
| ğŸ“Š **Latency Metrics**     | End-to-end pipeline latency tracking: STT â†’ LLM â†’ TTS per request              |
| ğŸŒ **WebSocket Streaming** | Binary audio + JSON control protocol with chunked delivery & heartbeat         |
| ğŸ›¡ï¸ **Error Handling**      | Graceful degradation, fallback TTS responses, clean session teardown           |

---

## Project Structure

```
AIVoiceAgent/
â”‚
â”œâ”€â”€ main.py                          # Entry point â€” orchestrates all services
â”œâ”€â”€ client.html                      # Browser-based voice client (open in browser)
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ .env                             # Your API keys (gitignored)
â”œâ”€â”€ README.md
â”‚
â””â”€â”€ app/
    â”œâ”€â”€ __init__.py
    â”‚
    â”œâ”€â”€ config/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ config.py                # Central configuration (API keys, models, settings)
    â”‚
    â”œâ”€â”€ ws/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ ws_handler.py            # WebSocket server (binary audio + JSON control)
    â”‚
    â””â”€â”€ services/
        â”œâ”€â”€ __init__.py
        â”‚
        â”œâ”€â”€ deepgram/
        â”‚   â”œâ”€â”€ __init__.py
        â”‚   â”œâ”€â”€ stt.py               # Deepgram streaming Speech-to-Text
        â”‚   â””â”€â”€ tts.py               # Deepgram Text-to-Speech (with retry)
        â”‚
        â”œâ”€â”€ llm/
        â”‚   â”œâ”€â”€ __init__.py
        â”‚   â”œâ”€â”€ provider.py          # Multi-provider LLM (OpenAI-compatible + Anthropic)
        â”‚   â””â”€â”€ persona.py           # AI persona definition & system prompt
        â”‚
        â””â”€â”€ memory/
            â”œâ”€â”€ __init__.py
            â””â”€â”€ conversation_memory.py   # Per-session conversation history management
```

---

## Quick Start (Step-by-Step)

### Prerequisites

| Requirement      | Details                                                            |
| ---------------- | ------------------------------------------------------------------ |
| **Python**       | 3.10 or newer                                                      |
| **Deepgram key** | [console.deepgram.com](https://console.deepgram.com)               |
| **Groq key**     | [console.groq.com](https://console.groq.com) (free tier available) |
| **Browser**      | Chrome, Edge, or Firefox (for `client.html`)                       |
| **Microphone**   | Any mic â€” the browser will ask for permission                      |

### Step 1 â€” Navigate to the project

```bash
cd AIVoiceAgent
```

### Step 2 â€” Create & activate a virtual environment

```bash
# Create
python -m venv venv

# Activate (Windows PowerShell)
venv\Scripts\Activate.ps1

# Activate (Windows CMD)
venv\Scripts\activate.bat

# Activate (Linux / macOS)
source venv/bin/activate
```

### Step 3 â€” Install dependencies

```bash
pip install -r requirements.txt
```

### Step 4 â€” Configure environment variables

Edit the `.env` file in the project root and add your API keys:

```env
# Required
DEEPGRAM_API_KEY=your_deepgram_api_key
GROQ_API_KEY=your_groq_api_key

# Provider selection (default: groq)
LLM_PROVIDER=groq

WS_PORT=8080
```

> **Supported providers & their env vars:**
>
> | Provider    | Env Key             | Default Model              |
> | ----------- | ------------------- | -------------------------- |
> | `groq`      | `GROQ_API_KEY`      | `llama-3.3-70b-versatile`  |
> | `grok`      | `GROK_API_KEY`      | `grok-3`                   |
> | `openai`    | `OPENAI_API_KEY`    | `gpt-4o`                   |
> | `anthropic` | `ANTHROPIC_API_KEY` | `claude-sonnet-4-20250514` |
>
> Anthropic requires an extra install: `pip install anthropic>=0.20.0`

### Step 5 â€” Start the server

```bash
python main.py
```

You should see:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     ğŸ™ï¸  AI Voice Agent Starting      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

âœ… Configuration validated (LLM provider: groq)
âœ… All services initialized
ğŸ“‹ Configuration:
   LLM: GROQ (llama-3.3-70b-versatile)
   STT: Deepgram (nova-2)
   TTS: Deepgram (aura-asteria-en)
   WebSocket: ws://localhost:8080
ğŸ§ Waiting for client connections...
```

### Step 6 â€” Open the browser client

Open `client.html` in your browser (just double-click the file, or):

```bash
start client.html              # Windows
open client.html               # macOS
xdg-open client.html           # Linux
```

1. Click **ğŸ¤ Start** â€” connects to the WebSocket server and starts your microphone.
2. **Speak** â€” live transcription appears, then Nova's voice response plays back.
3. Click **â¹ï¸ Interrupt** to barge-in mid-response.
4. Click **ğŸ—‘ï¸ Clear** to reset conversation memory.
5. Click **â¹ Stop** to end the session.

---

## Configuration

All settings are in `app/config/config.py` and can be overridden via `.env`:

| Setting          | Env Variable       | Default      | Description                              |
| ---------------- | ------------------ | ------------ | ---------------------------------------- |
| Deepgram API Key | `DEEPGRAM_API_KEY` | â€”            | Required                                 |
| Groq API Key     | `GROQ_API_KEY`     | â€”            | Required (for default Groq provider)     |
| LLM Provider     | `LLM_PROVIDER`     | `groq`       | `groq` / `grok` / `openai` / `anthropic` |
| LLM Model        | `LLM_MODEL`        | per-provider | Override the default model               |
| LLM Temperature  | `LLM_TEMPERATURE`  | `0.7`        | Response creativity                      |
| LLM Max Tokens   | `LLM_MAX_TOKENS`   | `300`        | Max response length                      |
| WebSocket Port   | `WS_PORT`          | `8080`       | Server listen port                       |

Memory settings (in `config.py`):

- `max_messages`: Sliding window size (default: 20)
- `use_summarization`: Enable LLM-powered summarization (default: false)
- `summarize_after`: Trigger summarization threshold (default: 15)

---

## WebSocket Protocol

### Client â†’ Server

| Data Type | Description                                                 |
| --------- | ----------------------------------------------------------- |
| Binary    | Raw audio chunks (linear16, 16 kHz, mono)                   |
| JSON      | `{type: "end"}` / `{type: "clear"}` / `{type: "interrupt"}` |

### Server â†’ Client

| Message Type        | Payload                    | Description                       |
| ------------------- | -------------------------- | --------------------------------- |
| `connected`         | `{ sessionId, message }`   | Session established               |
| `transcript`        | `{ text, isFinal }`        | STT result (interim or final)     |
| `thinking`          | `{}`                       | LLM is generating a response      |
| `speaking`          | `{}`                       | First TTS sentence ready          |
| `audio_start`       | `{ sampleRate, encoding }` | Audio stream beginning            |
| _(binary)_          | Raw bytes                  | TTS audio chunks (linear16 24kHz) |
| `audio_end`         | `{}`                       | Audio stream complete             |
| `audio_interrupted` | `{}`                       | Barge-in: response cancelled      |
| `response`          | `{ text }`                 | Full AI response text             |
| `error`             | `{ message }`              | Error message                     |

---

## Tech Stack

| Component      | Technology                                     |
| -------------- | ---------------------------------------------- |
| **Runtime**    | Python 3.10+ / asyncio                         |
| **WebSocket**  | `websockets` library                           |
| **STT**        | Deepgram Nova-2 (streaming)                    |
| **TTS**        | Deepgram Aura (Asteria voice)                  |
| **LLM**        | Groq (default) / Grok / OpenAI / Anthropic     |
| **LLM Client** | `openai` SDK (OpenAI-compatible API)           |
| **Config**     | `python-dotenv`                                |
| **Frontend**   | Vanilla HTML/JS (Web Audio API, WebSocket API) |

---

## Troubleshooting

| Issue                        | Fix                                                                                |
| ---------------------------- | ---------------------------------------------------------------------------------- |
| `Missing required API keys`  | Check your `.env` file has the correct keys for your chosen provider               |
| Mic not working in browser   | Ensure you're on `localhost` or HTTPS â€” browsers block mic on insecure origins     |
| No audio playback            | Click somewhere on the page first (browsers require user interaction before audio) |
| WebSocket connection refused | Ensure `python main.py` is running and the port matches `client.html` settings     |
| Anthropic provider           | Not bundled by default â€” run `pip install anthropic>=0.20.0` if needed             |
